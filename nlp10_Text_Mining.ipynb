{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp10_Text Mining.ipynb",
      "provenance": [],
      "mount_file_id": "1MZmKVWna4eFfxTaihhbZ48zNh07eIZf5",
      "authorship_tag": "ABX9TyM380AeNJi0F881b4xatKKc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/copiglet/Caba_nlp/blob/main/nlp10_Text_Mining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23YS1vJ07SGF"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtIBMYv46hho",
        "outputId": "f8e8b968-5d3f-408d-d73c-84315cd6084f"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v54yAV3pDFJ6",
        "outputId": "fc21f3ac-0e2e-49c5-bee5-cb3eb66a992d"
      },
      "source": [
        "# 문장 토큰화(sent tokenize) : 마침표, 개행문자(\\n), 정규표현식\r\n",
        "from nltk import sent_tokenize\r\n",
        "text_sample = 'The Matrix is everywhere its all around us, here even in this room. \\\r\n",
        "               You can see it out your window or on your television. \\\r\n",
        "               You feel it when you go to work, or go to church or pay your taxes.'\r\n",
        "sentences = sent_tokenize(text=text_sample)\r\n",
        "print(sentences)\r\n",
        "print(type(sentences), len(sentences))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The Matrix is everywhere its all around us, here even in this room.', 'You can see it out your window or on your television.', 'You feel it when you go to work, or go to church or pay your taxes.']\n",
            "<class 'list'> 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGgC9WUeEWuu",
        "outputId": "0df0262d-8eeb-47d8-c19d-e93da1f5983c"
      },
      "source": [
        "# 단어 토큰화(word_tokenize) : 공백, 콤마, 마침표, 개행문자, 정규표현식\r\n",
        "from nltk import word_tokenize\r\n",
        "\r\n",
        "sentence = 'The Matrix is everywhere its all around us, here even in this room.'\r\n",
        "words = word_tokenize(sentence)\r\n",
        "print(words)\r\n",
        "print(type(words),len(words))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.']\n",
            "<class 'list'> 15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmAlvKCWFb9f",
        "outputId": "1593867b-8c75-4cfd-ba3a-3e13133bd7c4"
      },
      "source": [
        "# 문서에 대해서 모든 단어를 토큰화\r\n",
        "from nltk import word_tokenize, sent_tokenize\r\n",
        "\r\n",
        "def tokenize_text(text):\r\n",
        "  sentences = sent_tokenize(text) # 문장별 분리 토큰\r\n",
        "  word_tokens = [word_tokenize(sentence) for sentence in sentences] # 문장별 단어 토큰화\r\n",
        "  return word_tokens\r\n",
        "\r\n",
        "word_tokens = tokenize_text(text_sample)\r\n",
        "print(word_tokens)\r\n",
        "print(type(word_tokens), len(word_tokens))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.'], ['You', 'can', 'see', 'it', 'out', 'your', 'window', 'or', 'on', 'your', 'television', '.'], ['You', 'feel', 'it', 'when', 'you', 'go', 'to', 'work', ',', 'or', 'go', 'to', 'church', 'or', 'pay', 'your', 'taxes', '.']]\n",
            "<class 'list'> 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlybXL7oHsEX",
        "outputId": "b34d4a43-94b9-41c8-ce3c-b8b053eb532a"
      },
      "source": [
        "# 스톱워드 제거 : the, is, a, will와 같이 문맥적으로 큰 의미가 없는 단어를 제거\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZfKd92oHcAw",
        "outputId": "5ce608c3-a026-444c-f4d6-39c7efad5048"
      },
      "source": [
        "# NLTK english stopwords 갯수 확인\r\n",
        "print(len(nltk.corpus.stopwords.words('english'))) # corpus = 형태소\r\n",
        "print(nltk.corpus.stopwords.words('english')[:20])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "179\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgVhGbJTI2-5",
        "outputId": "9a5acf0d-1888-4ac9-c3a3-83d8191ceca5"
      },
      "source": [
        "# stopwords 필터링을 통한 제거\r\n",
        "import nltk\r\n",
        "stopwords = nltk.corpus.stopwords.words('english')\r\n",
        "all_tokens = []\r\n",
        "for sentence in word_tokens:\r\n",
        "  filtered_words = []\r\n",
        "  for word in sentence:\r\n",
        "    word = word.lower()\r\n",
        "    if word not in stopwords:\r\n",
        "      filtered_words.append(word)\r\n",
        "  all_tokens.append(filtered_words)\r\n",
        "print(all_tokens)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['matrix', 'everywhere', 'around', 'us', ',', 'even', 'room', '.'], ['see', 'window', 'television', '.'], ['feel', 'go', 'work', ',', 'go', 'church', 'pay', 'taxes', '.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UvKBq6KKXkP",
        "outputId": "5fb9be1c-f2ab-4a20-94ce-0ce6874eb49b"
      },
      "source": [
        "# 문법적 또는 의미적으로 변화하는 단어의 원형을 찾는 방법\r\n",
        "# Stemmer(LancasterStemmer)\r\n",
        "from nltk.stem import LancasterStemmer\r\n",
        "stemmer = LancasterStemmer()\r\n",
        "print(stemmer.stem('working'),stemmer.stem('works'),stemmer.stem('worked'))\r\n",
        "print(stemmer.stem('amusing'),stemmer.stem('aumses'),stemmer.stem('amused'))\r\n",
        "print(stemmer.stem('fancier'),stemmer.stem('fanciest'))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "work work work\n",
            "amus aums amus\n",
            "fant fanciest\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcmLxih0MsHi",
        "outputId": "2b1b7461-6a10-4719-e343-dda36244a125"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRNDtEv_LQEK",
        "outputId": "c2250184-c9f7-4117-8018-5d30698a5fcf"
      },
      "source": [
        "# Lemmatization(WordNetLemmatizer) : 정확한 원형 단어 추출을 위해 단어의 품사를 직접 입력\r\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\r\n",
        "\r\n",
        "lemma = WordNetLemmatizer()\r\n",
        "print(lemma.lemmatize('working','v'),lemma.lemmatize('works','v'),lemma.lemmatize('worked','v'))\r\n",
        "print(lemma.lemmatize('amusing','v'),lemma.lemmatize('aumses','v'),lemma.lemmatize('amused','v'))\r\n",
        "print(lemma.lemmatize('fancier','a'),lemma.lemmatize('fanciest','a'))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "work work work\n",
            "amuse aumses amuse\n",
            "fancy fancy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZuUfAgFM4Kv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}